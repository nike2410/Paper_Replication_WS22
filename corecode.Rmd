---
title: "corecode"
output: html_document
date: "2022-10-18"
---
```{r Activating Packages} 
#activating packages

library(lubridate)
library(dplyr)
library(tidyr)
library(readr)
library(readxl)
library(fmdates)
library(zoo)
library(moments)
library(lubridate)
library(xts)
library(HARModel)
library(slider)
library(broom)
library(tidyverse)
library(psych)
```

###############################################
#####CALCULATION PRICE OF CO-SKEWNESS RISK#####
###############################################

```{r Risk-Neutral Second Moment}
data_VIX <- as.data.frame(read.csv("^VXO.csv"))

data_VIX <- data_VIX %>% mutate(Date = ymd(Date))
data_VIX$Year = as.numeric(format(as.Date(data_VIX$Date, format='%Y%m%d'),"%Y"))
data_VIX$Month = as.numeric(format(as.Date(data_VIX$Date, format='%Y%m%d'),"%m")) 
data_VIX$Day = as.numeric(format(as.Date(data_VIX$Date, format='%Y%m%d'),"%d"))

data_VIX$numday <- as.numeric(format(as.Date(data_VIX$Date), '%Y%m%d'))

#Calculated risk-neutral second moment just taking square -- SqPrice -- and (x/100)^2 -- Square -- 
data_VIX$Adj.Close <- as.numeric(data_VIX$Adj.Close)
data_VIX <- select(data_VIX, -c(Open, Low, High, Close, Volume)) %>% 
  filter(numday < 20130101 & numday >= 19860101) %>% 
  mutate(RNSM=(Adj.Close/100)^2)
```
```{r Physical second moment}
#Implementing formula 19 to calculate daily varience

#Changing data formats
data_SNP500 <- read.csv("MCD.csv") %>% as.data.frame() %>% as_tibble()

data_SNP500 <- data_SNP500 %>% mutate(Date = ymd(Date)) 
data_SNP500$Year = format(as.Date(data_SNP500$Date, format='%Y%m%d'),"%Y") 
data_SNP500$Month = format(as.Date(data_SNP500$Date, format='%Y%m%d'),"%m") 
data_SNP500$Day = format(as.Date(data_SNP500$Date, format='%Y%m%d'),"%d") 

data_SNP500$numday <- as.numeric(format(as.Date(data_SNP500$Date), '%Y%m%d'))

data_SNP500 <- data_SNP500 %>% select(-c(Volume))


#Formula 19 from the paper (calculation of implied volatility)

data_SNP500 <- data_SNP500 %>%  mutate(Day_Vol = (log(High/Open) * (log(High/Open) - log(Close/Open))) + (log(Low/Open) * (log(Low/Open) - log(Close/Open))))


#Formula 18 (calculation of daily, weekly, monthly volatilities)

data_SNP500 <- data_SNP500 %>% 
  mutate(
    VK = slide_dbl(data_SNP500$Day_Vol, ~sum(.x), .after=30, .complete = TRUE),
    V2 = slide_dbl(data_SNP500$Day_Vol, ~sum(.x), .before = 1, .complete = TRUE),
    V5 = slide_dbl(data_SNP500$Day_Vol, ~sum(.x), .before = 4, .complete = TRUE),
    V21 = slide_dbl(data_SNP500$Day_Vol, ~sum(.x), .before = 20, .complete = TRUE)) 


#HAR model for Formula 17. From this model we will get coefficients to calculate the estimation of physical second moments.

regression_summary <- function(data_SNP500){
    reg <- lm(VK ~ V2+V5+V21, data=data_SNP500)
    return(tibble("date"=(data_SNP500$Date),
                  "phi0"=coef(reg)[1],
                  "phi1"=coef(reg)[2],
                  "phi2"=coef(reg)[3],
                  "phi3"=coef(reg)[4]))
}

Reg_SNP500 <- data_SNP500 %>% 
  summarise(model = slide_period(
    .x = cur_data(),
    .i = Date,
    .period="month",
    .f = regression_summary,
    .before = 120,
    .complete = TRUE
  )) %>% unnest(model) %>% distinct(date, .keep_all = TRUE)


data_SNP500 <- data_SNP500 %>%
  mutate(
    phi0 = Reg_SNP500$phi0,
    phi1 = Reg_SNP500$phi1,
    phi2 = Reg_SNP500$phi2,
    phi3 = Reg_SNP500$phi3,
    PSM = phi0 + phi1*V2 + phi2*V5 + phi3*V21 
  ) %>%
  filter(numday >= 19860203 & numday < 20130101) %>% 
  group_by(Year, Month) %>%
  filter(numday == max(numday))
```

```{r Price of Co-skewness Risk}
CS_Price <- tibble(
  Date = data_SNP500$Date,
  Price = data_SNP500$PSM - data_VIX$RNSM
)
```
```{r Figure 1}
#Now we are finalizing the Figure 1. for this, we save it in PDF format
pdf("Figure 1.pdf",         # File name
    width = 8, height = 7, # Width and height in inches
    bg = "white",          # Background color
    colormodel = "cmyk",    # Color model (cmyk is required for most publications)
    paper = "A4")
par(mfrow = c(3,1))
plot(data_SNP500$Date,data_SNP500$PSM, type="l",
     xlab = "", ylab = "",
     main = "Graph A. Physical Second Moment", font.main = 3)
plot(data_VIX$Date,data_VIX$RNSM, type="l", 
     xlab = "", ylab = "",
     main ="Graph B. Risk-Neutral Second Moment", font.main = 3)
plot(CS_Price$Date,CS_Price$Price, type = "l", 
     xlab = "", ylab = "",
     main = "Graph C. Price of Coskewness Risk", font.main = 3)
dev.off() 
```
```{r Table 1}
library(gridExtra)
#Calculation first-order autocorrelation with OLS and take the square root of 
#of the R^2 from regretions.
foc1 <- lm(PSM ~ lag(PSM, n = 1L), data_SNP500)
foc2 <- lm(RNSM ~ lag(RNSM, n = 1L), data_VIX)
foc3 <- lm(Price ~ lag(Price, n = 1L), CS_Price)
focs <- c(summary(foc1)$r.square, summary(foc2)$r.square, 
          summary(foc3)$r.square)
Table_1 <- rbind(
  cbind(
  t(select(table_PSM, c("mean", "sd", "skew", "kurtosis"))),
  t(select(table_RNSM, c("mean", "sd", "skew", "kurtosis"))),
  t(select(table_CSP, c("mean", "sd", "skew", "kurtosis")))
), focs
)
colnames(Table_1) <- c("Physical Second Moment", "Risk-Neutral Second Moment", "Price of Coskewness Risk")
rownames(Table_1) <- c("mean", "sd", "skew", "kurtosis","Autocorrelation")

pdf("Table 1.pdf", width = 10, height = 5)
grid.table(Table_1)
dev.off()
```

```{r}
table_RNSM<-describe(data_VIX$RNSM)
plot(data_VIX$Date,data_VIX$RNSM, type="l")

table_PSM<-describe(data_SNP500$PSM)
plot(data_SNP500$Date,data_SNP500$PSM, type="l")

table_CSP<-describe(CS_Price$Price)
plot(CS_Price$Date,CS_Price$Price, type = "l")
```
```{r Fama-French regressions}
#To obtain the data for Fama-French models, we use the following FFdownload package and copy the code from https://sstoeckl.github.io/ffdownload/
#We install the library
library(FFdownload)
#Then we process the data from the website to see, what files we can get (FFlist)
temptxt <- tempfile(fileext = ".txt")
FFdownload(exclude_daily=TRUE,download=FALSE,download_only=TRUE,listsave=temptxt)
FFlist <- readr::read_csv(temptxt) %>% dplyr::select(2) %>% dplyr::rename(Files=x)
FFlist %>% dplyr::slice(1:3,(dplyr::n()-2):dplyr::n())

#Now we specify the name of files that we actually need to download. Input vector is responsible to collect the names, so that row needs to be edited. Then it is used for the download
tempd <- tempdir()
inputlist <- c("25_Portfolios_5x5","25_Portfolios_ME_Prior_12_2","25_Portfolios_ME_Prior_1_0","25_Portfolios_ME_Prior_60_13","F-F_Research_Data_Factors","F-F_Momentum_Factor")
FFdownload(exclude_daily=TRUE,tempd=tempd,download=TRUE,download_only=TRUE,inputlist=inputlist)

tempf <- paste0(tempd,"\\FFdata.RData")
getwd()
FFdownload(output_file = tempf, exclude_daily=TRUE,tempd=tempd,download=FALSE,
           download_only=FALSE,inputlist = inputlist, format="tbl")

library(timetk)
load(file = tempf)

#Making datasets for portfolios. We also filter data for a date frame same as for the whole research

#For Size and Book-Market portfolios
Size.Book_25 <- FFdata$x_25_Portfolios_5x5$monthly$average_value_weighted_returns %>% 
  left_join(FFdata$`x_F-F_Research_Data_Factors`$monthly$Temp2, by="date") %>%
  left_join(FFdata$`x_F-F_Momentum_Factor`$monthly$Temp2, by = "date")%>%
  filter(date > "Jan 1986") %>% filter(date < "Sep 2021")

#For Size and Momentum portfolios
Size.Momentum_25 <- FFdata$x_25_Portfolios_ME_Prior_12_2$monthly$average_value_weighted_returns %>% 
  left_join(FFdata$`x_F-F_Research_Data_Factors`$monthly$Temp2, by="date") %>%
  left_join(FFdata$`x_F-F_Momentum_Factor`$monthly$Temp2, by = "date")%>%
  filter(date > "Jan 1986") %>% filter(date < "Sep 2021")

#For Size and Long-term reversal
Size.LTR_25 <- FFdata$x_25_Portfolios_ME_Prior_60_13$monthly$average_value_weighted_returns %>% 
  left_join(FFdata$`x_F-F_Research_Data_Factors`$monthly$Temp2, by="date") %>%
  left_join(FFdata$`x_F-F_Momentum_Factor`$monthly$Temp2, by = "date")%>%
  filter(date > "Jan 1986") %>% filter(date < "Sep 2021")

#For Size and Short-term reversal
Size.STR_25 <- FFdata$x_25_Portfolios_ME_Prior_1_0$monthly$average_value_weighted_returns %>% 
  left_join(FFdata$`x_F-F_Research_Data_Factors`$monthly$Temp2, by="date") %>%
  left_join(FFdata$`x_F-F_Momentum_Factor`$monthly$Temp2, by = "date") %>%
  filter(date > "Jan 1986") %>% filter(date < "Sep 2021")
  



```










#HAR model for Formula 17. From this model we will get coefficients to calculate the estimation of physical second moments.
regression_summary <- function(df){
    reg <- lm(VK ~ V2+V4+V20, data=df)
    return(tibble(date=Date,
      "phi0"=coef(reg)[1],
                  "phi1"=coef(reg)[2],
                  "phi2"=coef(reg)[3],
                  "phi3"=coef(reg)[4]))
}
FANG_ret2 %>%
  summarise(model = slide_period(
    .x = cur_data(),
    .i = date,
    .period="month",
    .f = regression_summary,
    .before = 1,
    .complete = FALSE
  )) %>% unnest(model) 


table <- slide_period(data_SNP500,data_SNP500$Date,.period = "year",identity,.every = 10, .before = 9)
################################################################
#I AM NOW HERE, trying to implement recursive regression

```

```{r Example for HAR model}
# Example 1: HAR
# Forecasting daily Realized volatility for the S&P 500 using the basic HARmodel: HAR
library(xts)
RVSPY <- as.xts(SPYRM$RV5, order.by = SPYRM$DT)

x <- HARmodel(data = RVSPY , periods = c(1,5,22), RVest = c("rCov"),
              type = "HAR", h = 1, transform = NULL, inputType = "RM")
class(x)
x
summary(x)
plot(x)
predict(x)
```

```{r JUNK}
#JUNK


library(psych)
table1_data<-describe(data_VIX$Square)
plot(data_VIX$Date,data_VIX$Square, type="l")
table1.2_data<-describe(data_VIX$SqPrice)
plot(data_VIX$Date,data_VIX$SqPrice, type="l")
table2.1<-describe(data_SNP500$PSM)
plot(data_SNP500$Date,data_SNP500$PSM, type="l")

n <- 15
x <- rnorm(n)
weights <- 0.9 ^ (n:1)

# rolling sums with complete windows
roll_sum(x, 5)
x

#Getting data for HAR model: filtering until 1996 (10 year window)
win_120 <- data_SNP500 %>% filter(numday <=19960203)

which(data_SNP500 = (head(data_SNP500$numday,1)+100000), arr.ind = TRUE)

a1

HAR_data <- as.xts(win_120$Day_Vol, order.by = win_120$Date)
x <- HARmodel(data = HAR_data , periods = c(1,4,20), RVest = c("rCov"), type = "HAR", h = 1, transform = NULL, inputType = "RM")
summary(x)

#calculating volatilities based on estimates from HAR model: formula 17
coefs <- coefficients(x)

#This How I want this to look like
data_SNP500 <- data_SNP500 %>% mutate(estimated_volatility = coefs[1] + coefs[2]*rollsum(Day_Vol,1) + coefs[3]*Wek_Vol + coefs[4]*Mon_Vol)

rolling_lms <- lapply(seq(20,nrow(df) ), function(x) lm( Y ~ X1+X2, data = df[1:x , ]) )
```





















